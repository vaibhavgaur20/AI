{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_excel(\"Input.xlsx\",engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        2\n",
      "2        3\n",
      "3        4\n",
      "4        5\n",
      "      ... \n",
      "165    167\n",
      "166    168\n",
      "167    169\n",
      "168    170\n",
      "169    171\n",
      "Name: URL_ID, Length: 170, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "urls = dataset['URL']\n",
    "url_ids = dataset['URL_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings =[]\n",
    "contents =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for url in urls:\n",
    "    \n",
    "#     dummy_list = []\n",
    "    \n",
    "#     driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "   \n",
    "#     driver.get(url)\n",
    "\n",
    "#     title = driver.find_elements(By.XPATH,\"//h1[contains(@class,'entry-title')]\")\n",
    "#     headings.append(title[0].text)\n",
    "\n",
    "#     paragraphs = driver.find_elements(By.XPATH,\"//p\")\n",
    "#     for para in paragraphs:\n",
    "#         dummy_list.append(para.text)\n",
    "        \n",
    "#     x = \" \".join(dummy_list)  \n",
    "#     contents.append(x)\n",
    "#     driver.quit()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m spacy download en_core_web_sm\n",
    "\n",
    "# -m pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings_df = pandas.DataFrame(headings)\n",
    "contents_df = pandas.DataFrame(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.concat([headings_df,contents_df],axis=1,join ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the extracted data in excel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = pandas.ExcelWriter(r'test_internship_writer.xlsx')\n",
    "# df.to_excel(writer,sheet_name = 'headings', index=False)\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_data = pandas.read_excel(\"test_internship_writer.xlsx\",engine='openpyxl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fetched_data[0]\n",
    "y = fetched_data['0.1']\n",
    "url_ids = fetched_data['URL_ID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(fetched_data)):\n",
    "    \n",
    "#     with open(\"./text_files/{}\".format(fetched_data.loc[i,\"URL_ID\"]), 'w') as f:\n",
    "#         f.write(fetched_data.loc[i,0])\n",
    "#         f.write('\\n')\n",
    "#         f.write(fetched_data.loc[i,'0.1'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(fetched_data)):\n",
    "    \n",
    "#     with open(\"./text_files/{}\".format(fetched_data.loc[i,\"URL_ID\"]), 'r') as f:\n",
    "#         s = f.read()\n",
    "#         subjectivity = TextBlob(s).sentiment.subjectivity\n",
    "#         polarity = TextBlob(y[i]).sentiment.polarity\n",
    "#         print(subjectivity,\" \", polarity)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Sentence Length & Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./text_files/1\", 'r') as f:\n",
    "#     s = f.read()\n",
    "#     print(avg_sentence_length(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(fetched_data)):\n",
    "    \n",
    "#     with open(\"./text_files/{}\".format(fetched_data.loc[i,\"URL_ID\"]), 'r') as f:\n",
    "#         s = f.read()\n",
    "#         print(avg_sentence_length(s))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syllable Count, Fog Index, avg. Word Length & Personal Pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syllable - 1121\n",
      "Fog index - 14.61\n",
      "personal pronoun- 4\n",
      "Average word length - 5.188118811881188\n"
     ]
    }
   ],
   "source": [
    "with open(\"./text_files/1\", 'r') as f:\n",
    "    s = f.read()\n",
    "    print('Syllable -',textstat.syllable_count(s))\n",
    "    print('Fog index -',textstat.gunning_fog(s))\n",
    "    \n",
    "    pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "    pronouns = pronounRegex.findall(s)\n",
    "    print('personal pronoun-',len(pronouns))\n",
    "    \n",
    "    words = s.split()\n",
    "    average = sum(len(word) for word in words) / len(words)\n",
    "    print('Average word length -', average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable(word):\n",
    "    \n",
    "    vowels=['a','e','i','o','u']\n",
    "    syllable_counter =0\n",
    "    \n",
    "    for i in range(len(word)-1): \n",
    "        if word[i] == 'e' and (word[i+1]  == 'd' or word[i+1]  == 's' ):\n",
    "            continue\n",
    "        for vowel in vowels:\n",
    "            if word[i] == vowel:\n",
    "                syllable_counter += 1\n",
    "        \n",
    "      \n",
    "    return syllable_counter\n",
    "            \n",
    "    \n",
    "def avg_sentence_length(text):\n",
    "    \n",
    "    sentences = text.split(\".\")\n",
    "    words = text.split(\" \")\n",
    "    \n",
    "    return len(words)/len(sentences)\n",
    "\n",
    "def Percentage_Complex_words(text):\n",
    "    words = text.split(\" \")\n",
    "    complex_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if (syllable(word) >2):\n",
    "            complex_words.append(word)\n",
    "            \n",
    "    return (len(complex_words)/len(words))*100, len(complex_words)\n",
    "\n",
    "def Fog_Index(text):\n",
    "    \n",
    "    return 0.4 * (avg_sentence_length(text) + Percentage_Complex_words(text)[0])\n",
    "\n",
    "def Average_Number_of_Words_Per_Sentence(text):\n",
    "    sentences = text.split(\".\")\n",
    "    words = text.split(\" \")\n",
    "    \n",
    "    return len(words)/len(sentences)\n",
    "\n",
    "def Average_Word_Length(text):\n",
    "    \n",
    "    sum_of_characters = 0 \n",
    "    words = text.split(\" \")\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        sum_of_characters += len(word)\n",
    "        \n",
    "    return sum_of_characters/len(words)\n",
    "\n",
    "def Polarity_Score(P,N):\n",
    "    return (P - N)/((P + N)+ 0.000001)\n",
    "\n",
    "def Subjectivity_Score(stopwords_removed_list,P,N):\n",
    "    \n",
    "    return (P+N)/(len(stopwords_removed_list) + 0.000001)\n",
    "\n",
    "def Positive_Negative_Score(stopwords_removed_list, Master_Dictionary_list):\n",
    "    \n",
    "    Positive_counter = 0\n",
    "    Negative_counter = 0\n",
    "    \n",
    "    for stopword in stopwords_removed_list:\n",
    "        for i in range(len(Master_dictionary_list)):  \n",
    "            if stopword.upper() == Master_dictionary_list[i][0]:\n",
    "                if Master_dictionary_list[i][1] != 0 :\n",
    "                    Positive_counter += 1\n",
    "                elif Master_dictionary_list[i][2] != 0:\n",
    "                    Negative_counter += 1\n",
    "        \n",
    "    return Positive_counter,Negative_counter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_SCORE=[]\n",
    "NEGATIVE_SCORE=[]\n",
    "POLARITY_SCORE=[]\n",
    "SUBJECTIVITY_SCORE=[]\n",
    "AVG_SENTENCE_LENGTH=[]\n",
    "PERCENTAGE_OF_COMPLEX_WORDS=[]\n",
    "FOG_INDEX=[]\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=[]\n",
    "COMPLEX_WORD_COUNT=[]\n",
    "WORD_COUNT=[]\n",
    "SYLLABLE_PER_WORD=[]\n",
    "PERSONAL_PRONOUNS=[]\n",
    "AVG_WORD_LENGTH=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise objects\n",
    "\n",
    "# 'r' stands for Regular Expression and '\\w+' indicates that include All Words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Only calling english stopwords\n",
    "en_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removed(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    new_tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "Master_Dictionary = pandas.read_csv(\"Loughran-McDonald_MasterDictionary_1993-2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "Master_dictionary_list = []\n",
    "\n",
    "for i in range(len(Master_Dictionary)):            \n",
    "    if Master_Dictionary['Positive'][i] != 0 :\n",
    "        Master_dictionary_list.append([Master_Dictionary['Word'][i],1,0])\n",
    "    elif Master_Dictionary['Negative'][i] != 0:\n",
    "        Master_dictionary_list.append([Master_Dictionary['Word'][i],0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "\n",
    "for i in range(len(fetched_data)):\n",
    "    \n",
    "    with open(\"./text_files/{}\".format(fetched_data.loc[i,\"URL_ID\"]), 'r') as f:\n",
    "        s = f.read()\n",
    "        \n",
    "        stopwords_removed_list = stopwords_removed(s)\n",
    "        \n",
    "        P = Positive_Negative_Score(stopwords_removed_list, Master_dictionary_list)[0]\n",
    "        N = Positive_Negative_Score(stopwords_removed_list, Master_dictionary_list)[1]\n",
    "        \n",
    "        \n",
    "        pronouns = pronounRegex.findall(s)\n",
    "        \n",
    "        POSITIVE_SCORE.append(P)\n",
    "        NEGATIVE_SCORE.append(N)\n",
    "        POLARITY_SCORE.append(Polarity_Score(P,N))\n",
    "        SUBJECTIVITY_SCORE.append(Subjectivity_Score(stopwords_removed_list,P,N))\n",
    "        AVG_SENTENCE_LENGTH.append(avg_sentence_length(s))\n",
    "        PERCENTAGE_OF_COMPLEX_WORDS.append(Percentage_Complex_words(s)[0])\n",
    "        FOG_INDEX.append(Fog_Index(s))\n",
    "        AVG_NUMBER_OF_WORDS_PER_SENTENCE.append(Average_Number_of_Words_Per_Sentence(s))\n",
    "        COMPLEX_WORD_COUNT.append(Percentage_Complex_words(s)[1])\n",
    "        WORD_COUNT.append(len(stopwords_removed_list))\n",
    "        SYLLABLE_PER_WORD.append(syllable(s))\n",
    "        PERSONAL_PRONOUNS.append(len(pronouns))\n",
    "        AVG_WORD_LENGTH.append(Average_Word_Length(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_SCORE= pandas.DataFrame(POSITIVE_SCORE, columns=['POSITIVE_SCORE'])\n",
    "NEGATIVE_SCORE=pandas.DataFrame(NEGATIVE_SCORE, columns=['NEGATIVE_SCORE'])\n",
    "POLARITY_SCORE=pandas.DataFrame(POLARITY_SCORE, columns=['POLARITY_SCORE'])\n",
    "SUBJECTIVITY_SCORE=pandas.DataFrame(SUBJECTIVITY_SCORE, columns=['SUBJECTIVITY_SCORE'])\n",
    "AVG_SENTENCE_LENGTH=pandas.DataFrame(AVG_SENTENCE_LENGTH, columns=['AVG_SENTENCE_LENGTH'])\n",
    "PERCENTAGE_OF_COMPLEX_WORDS=pandas.DataFrame(PERCENTAGE_OF_COMPLEX_WORDS,columns=['PERCENTAGE_OF_COMPLEX_WORDS'])\n",
    "FOG_INDEX=pandas.DataFrame(FOG_INDEX,columns=['FOG_INDEX'])\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=pandas.DataFrame(AVG_NUMBER_OF_WORDS_PER_SENTENCE,columns=['AVG_NUMBER_OF_WORDS_PER_SENTENCE'])\n",
    "COMPLEX_WORD_COUNT=pandas.DataFrame(COMPLEX_WORD_COUNT,columns=['COMPLEX_WORD_COUNT'])\n",
    "WORD_COUNT=pandas.DataFrame(WORD_COUNT,columns=['WORD_COUNT'])\n",
    "SYLLABLE_PER_WORD=pandas.DataFrame(SYLLABLE_PER_WORD,columns=['SYLLABLE_PER_WORD'])\n",
    "PERSONAL_PRONOUNS=pandas.DataFrame(PERSONAL_PRONOUNS,columns=['PERSONAL_PRONOUNS'])\n",
    "AVG_WORD_LENGTH=pandas.DataFrame(AVG_WORD_LENGTH,columns=['AVG_WORD_LENGTH'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pandas.concat([\n",
    "url_ids,\n",
    "urls,\n",
    "POSITIVE_SCORE,\n",
    "NEGATIVE_SCORE,\n",
    "POLARITY_SCORE,\n",
    "SUBJECTIVITY_SCORE,\n",
    "AVG_SENTENCE_LENGTH,\n",
    "PERCENTAGE_OF_COMPLEX_WORDS,\n",
    "FOG_INDEX,\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE,\n",
    "COMPLEX_WORD_COUNT,\n",
    "WORD_COUNT,\n",
    "SYLLABLE_PER_WORD,\n",
    "PERSONAL_PRONOUNS,\n",
    "AVG_WORD_LENGTH],\n",
    "axis=1,join ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE_SCORE</th>\n",
       "      <th>NEGATIVE_SCORE</th>\n",
       "      <th>POLARITY_SCORE</th>\n",
       "      <th>SUBJECTIVITY_SCORE</th>\n",
       "      <th>AVG_SENTENCE_LENGTH</th>\n",
       "      <th>PERCENTAGE_OF_COMPLEX_WORDS</th>\n",
       "      <th>FOG_INDEX</th>\n",
       "      <th>AVG_NUMBER_OF_WORDS_PER_SENTENCE</th>\n",
       "      <th>COMPLEX_WORD_COUNT</th>\n",
       "      <th>WORD_COUNT</th>\n",
       "      <th>SYLLABLE_PER_WORD</th>\n",
       "      <th>PERSONAL_PRONOUNS</th>\n",
       "      <th>AVG_WORD_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.023753</td>\n",
       "      <td>25.214286</td>\n",
       "      <td>18.271955</td>\n",
       "      <td>17.394496</td>\n",
       "      <td>25.214286</td>\n",
       "      <td>129</td>\n",
       "      <td>421</td>\n",
       "      <td>1275</td>\n",
       "      <td>4</td>\n",
       "      <td>5.196884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>21.758621</td>\n",
       "      <td>22.979398</td>\n",
       "      <td>17.895207</td>\n",
       "      <td>21.758621</td>\n",
       "      <td>145</td>\n",
       "      <td>381</td>\n",
       "      <td>1199</td>\n",
       "      <td>2</td>\n",
       "      <td>5.410460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>22.896104</td>\n",
       "      <td>24.276801</td>\n",
       "      <td>18.869162</td>\n",
       "      <td>22.896104</td>\n",
       "      <td>428</td>\n",
       "      <td>1073</td>\n",
       "      <td>3339</td>\n",
       "      <td>13</td>\n",
       "      <td>5.474759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>29.466667</td>\n",
       "      <td>21.493213</td>\n",
       "      <td>20.383952</td>\n",
       "      <td>29.466667</td>\n",
       "      <td>95</td>\n",
       "      <td>256</td>\n",
       "      <td>851</td>\n",
       "      <td>1</td>\n",
       "      <td>5.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.066998</td>\n",
       "      <td>22.281250</td>\n",
       "      <td>22.159888</td>\n",
       "      <td>17.776455</td>\n",
       "      <td>22.281250</td>\n",
       "      <td>158</td>\n",
       "      <td>403</td>\n",
       "      <td>1320</td>\n",
       "      <td>21</td>\n",
       "      <td>5.164095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>167</td>\n",
       "      <td>https://insights.blackcoffer.com/role-big-data...</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.381818</td>\n",
       "      <td>0.066026</td>\n",
       "      <td>22.373134</td>\n",
       "      <td>20.680454</td>\n",
       "      <td>17.221435</td>\n",
       "      <td>22.373134</td>\n",
       "      <td>310</td>\n",
       "      <td>833</td>\n",
       "      <td>2744</td>\n",
       "      <td>15</td>\n",
       "      <td>5.206805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>168</td>\n",
       "      <td>https://insights.blackcoffer.com/sales-forecas...</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.072235</td>\n",
       "      <td>22.709677</td>\n",
       "      <td>27.698864</td>\n",
       "      <td>20.163416</td>\n",
       "      <td>22.709677</td>\n",
       "      <td>195</td>\n",
       "      <td>443</td>\n",
       "      <td>1389</td>\n",
       "      <td>0</td>\n",
       "      <td>5.794034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>169</td>\n",
       "      <td>https://insights.blackcoffer.com/detect-data-e...</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.843137</td>\n",
       "      <td>0.082258</td>\n",
       "      <td>16.701754</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>16.680702</td>\n",
       "      <td>16.701754</td>\n",
       "      <td>238</td>\n",
       "      <td>620</td>\n",
       "      <td>1875</td>\n",
       "      <td>6</td>\n",
       "      <td>5.641807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>170</td>\n",
       "      <td>https://insights.blackcoffer.com/data-exfiltra...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>17.178571</td>\n",
       "      <td>19.334719</td>\n",
       "      <td>14.605316</td>\n",
       "      <td>17.178571</td>\n",
       "      <td>93</td>\n",
       "      <td>269</td>\n",
       "      <td>851</td>\n",
       "      <td>11</td>\n",
       "      <td>4.948025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>171</td>\n",
       "      <td>https://insights.blackcoffer.com/impacts-of-co...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.055901</td>\n",
       "      <td>26.818182</td>\n",
       "      <td>15.932203</td>\n",
       "      <td>17.100154</td>\n",
       "      <td>26.818182</td>\n",
       "      <td>47</td>\n",
       "      <td>161</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0         1  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1         2  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2         3  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3         4  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4         5  https://insights.blackcoffer.com/how-artificia...   \n",
       "..      ...                                                ...   \n",
       "165     167  https://insights.blackcoffer.com/role-big-data...   \n",
       "166     168  https://insights.blackcoffer.com/sales-forecas...   \n",
       "167     169  https://insights.blackcoffer.com/detect-data-e...   \n",
       "168     170  https://insights.blackcoffer.com/data-exfiltra...   \n",
       "169     171  https://insights.blackcoffer.com/impacts-of-co...   \n",
       "\n",
       "     POSITIVE_SCORE  NEGATIVE_SCORE  POLARITY_SCORE  SUBJECTIVITY_SCORE  \\\n",
       "0                 4               6       -0.200000            0.023753   \n",
       "1                 9               6        0.200000            0.039370   \n",
       "2                35              23        0.206897            0.054054   \n",
       "3                 6               1        0.714286            0.027344   \n",
       "4                14              13        0.037037            0.066998   \n",
       "..              ...             ...             ...                 ...   \n",
       "165              17              38       -0.381818            0.066026   \n",
       "166              21              11        0.312500            0.072235   \n",
       "167               4              47       -0.843137            0.082258   \n",
       "168               4               4        0.000000            0.029740   \n",
       "169               4               5       -0.111111            0.055901   \n",
       "\n",
       "     AVG_SENTENCE_LENGTH  PERCENTAGE_OF_COMPLEX_WORDS  FOG_INDEX  \\\n",
       "0              25.214286                    18.271955  17.394496   \n",
       "1              21.758621                    22.979398  17.895207   \n",
       "2              22.896104                    24.276801  18.869162   \n",
       "3              29.466667                    21.493213  20.383952   \n",
       "4              22.281250                    22.159888  17.776455   \n",
       "..                   ...                          ...        ...   \n",
       "165            22.373134                    20.680454  17.221435   \n",
       "166            22.709677                    27.698864  20.163416   \n",
       "167            16.701754                    25.000000  16.680702   \n",
       "168            17.178571                    19.334719  14.605316   \n",
       "169            26.818182                    15.932203  17.100154   \n",
       "\n",
       "     AVG_NUMBER_OF_WORDS_PER_SENTENCE  COMPLEX_WORD_COUNT  WORD_COUNT  \\\n",
       "0                           25.214286                 129         421   \n",
       "1                           21.758621                 145         381   \n",
       "2                           22.896104                 428        1073   \n",
       "3                           29.466667                  95         256   \n",
       "4                           22.281250                 158         403   \n",
       "..                                ...                 ...         ...   \n",
       "165                         22.373134                 310         833   \n",
       "166                         22.709677                 195         443   \n",
       "167                         16.701754                 238         620   \n",
       "168                         17.178571                  93         269   \n",
       "169                         26.818182                  47         161   \n",
       "\n",
       "     SYLLABLE_PER_WORD  PERSONAL_PRONOUNS  AVG_WORD_LENGTH  \n",
       "0                 1275                  4         5.196884  \n",
       "1                 1199                  2         5.410460  \n",
       "2                 3339                 13         5.474759  \n",
       "3                  851                  1         5.352941  \n",
       "4                 1320                 21         5.164095  \n",
       "..                 ...                ...              ...  \n",
       "165               2744                 15         5.206805  \n",
       "166               1389                  0         5.794034  \n",
       "167               1875                  6         5.641807  \n",
       "168                851                 11         4.948025  \n",
       "169                509                  0         5.000000  \n",
       "\n",
       "[170 rows x 15 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['POSITIVE SCORE','NEGATIVE SCORE','POLARITY SCORE','SUBJECTIVITY SCORE','AVG SENTENCE LENGTH','PERCENTAGE OF COMPLEX WORDS','FOG INDEX','AVG NUMBER OF WORDS PER SENTENCE','COMPLEX WORD COUNT','WORD COUNT','SYLLABLE PER WORD','PERSONAL PRONOUNS','AVG WORD LENGTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pandas.ExcelWriter(r'Output_Data_Structure.xlsx')\n",
    "full_df.to_excel(writer,sheet_name = 'headings',\n",
    "            index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
